{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark: Partition Pruning & Predicate Pushdown Demo\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/YOUR_REPO/blob/main/PySpark_Partition_Pruning_Demo.ipynb)\n",
        "\n",
        "This notebook demonstrates two critical PySpark optimization techniques:\n",
        "1. **Partition Pruning** - Skipping entire data partitions\n",
        "2. **Predicate Pushdown** - Pushing filters to the file format level\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "notebook_header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Setup: Install PySpark and Java"
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Java (required for PySpark)\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Install PySpark\n",
        "!pip install pyspark -q\n",
        "\n",
        "print(\"‚úÖ Installation complete!\")"
      ],
      "metadata": {
        "id": "install_dependencies",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96206605-bb2b-4e8d-ae13-c4ce3188bebf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Installation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Java environment\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "# Import required libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, to_date\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "print(\"‚úÖ Imports successful!\")"
      ],
      "metadata": {
        "id": "setup_environment",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04dd86c-aab4-4180-a4da-f12d602fa01a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Imports successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîß Initialize Spark Session"
      ],
      "metadata": {
        "id": "spark_init_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PartitionPruning_PredicatePushdown\") \\\n",
        "    .config(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\") \\\n",
        "    .config(\"spark.driver.memory\", \"2g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"‚úÖ Spark Session initialized!\")\n",
        "print(f\"Spark Version: {spark.version}\")"
      ],
      "metadata": {
        "id": "initialize_spark",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac0a77c-4cc8-49eb-dc4d-a0cd7cf77e4a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Spark Session initialized!\n",
            "Spark Version: 3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Create Sample Data"
      ],
      "metadata": {
        "id": "data_creation_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample orders data\n",
        "sample_data = {\n",
        "    'OrderID': list(range(1, 101)),\n",
        "    'OrderName': [f'Order_{chr(65 + i % 26)}' for i in range(100)],\n",
        "    'Customer': ['John', 'Jane', 'Bob', 'Alice', 'Charlie'] * 20,\n",
        "    'Date': ['21-12-1999', '22-12-1999', '23-12-1999', '24-12-1999', '25-12-1999'] * 20\n",
        "}\n",
        "\n",
        "# Create pandas DataFrame and save as CSV\n",
        "df_pandas = pd.DataFrame(sample_data)\n",
        "df_pandas.to_csv('/content/orders_sample.csv', index=False)\n",
        "\n",
        "print(\"‚úÖ Sample orders data created successfully!\")\n",
        "print(f\"\\nTotal records: {len(df_pandas)}\")\n",
        "print(\"\\nSample data:\")\n",
        "df_pandas.head(10)"
      ],
      "metadata": {
        "id": "create_sample_data",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "f02b1ed4-6d4a-49ba-e2b5-7b8ca30ace8b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sample orders data created successfully!\n",
            "\n",
            "Total records: 100\n",
            "\n",
            "Sample data:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   OrderID OrderName Customer        Date\n",
              "0        1   Order_A     John  21-12-1999\n",
              "1        2   Order_B     Jane  22-12-1999\n",
              "2        3   Order_C      Bob  23-12-1999\n",
              "3        4   Order_D    Alice  24-12-1999\n",
              "4        5   Order_E  Charlie  25-12-1999\n",
              "5        6   Order_F     John  21-12-1999\n",
              "6        7   Order_G     Jane  22-12-1999\n",
              "7        8   Order_H      Bob  23-12-1999\n",
              "8        9   Order_I    Alice  24-12-1999\n",
              "9       10   Order_J  Charlie  25-12-1999"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad6181db-2504-4dbe-b272-3486a0dbf0b0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OrderID</th>\n",
              "      <th>OrderName</th>\n",
              "      <th>Customer</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Order_A</td>\n",
              "      <td>John</td>\n",
              "      <td>21-12-1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Order_B</td>\n",
              "      <td>Jane</td>\n",
              "      <td>22-12-1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Order_C</td>\n",
              "      <td>Bob</td>\n",
              "      <td>23-12-1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Order_D</td>\n",
              "      <td>Alice</td>\n",
              "      <td>24-12-1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Order_E</td>\n",
              "      <td>Charlie</td>\n",
              "      <td>25-12-1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Order_F</td>\n",
              "      <td>John</td>\n",
              "      <td>21-12-1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Order_G</td>\n",
              "      <td>Jane</td>\n",
              "      <td>22-12-1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Order_H</td>\n",
              "      <td>Bob</td>\n",
              "      <td>23-12-1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Order_I</td>\n",
              "      <td>Alice</td>\n",
              "      <td>24-12-1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Order_J</td>\n",
              "      <td>Charlie</td>\n",
              "      <td>25-12-1999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad6181db-2504-4dbe-b272-3486a0dbf0b0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad6181db-2504-4dbe-b272-3486a0dbf0b0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad6181db-2504-4dbe-b272-3486a0dbf0b0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5cd70d1b-d459-4678-ae45-a249b75e794f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5cd70d1b-d459-4678-ae45-a249b75e794f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5cd70d1b-d459-4678-ae45-a249b75e794f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_pandas",
              "summary": "{\n  \"name\": \"df_pandas\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"OrderID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29,\n        \"min\": 1,\n        \"max\": 100,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          84,\n          54,\n          71\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OrderName\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"Order_I\",\n          \"Order_Q\",\n          \"Order_A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Customer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Jane\",\n          \"Charlie\",\n          \"Bob\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"22-12-1999\",\n          \"25-12-1999\",\n          \"23-12-1999\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì• Step 1: Read Raw Data"
      ],
      "metadata": {
        "id": "read_data_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_path = \"/content/orders_sample.csv\"\n",
        "\n",
        "df_raw = spark.read \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .csv(raw_path)\n",
        "\n",
        "print(\"Raw Data Schema:\")\n",
        "df_raw.printSchema()\n",
        "\n",
        "print(\"\\nSample Records:\")\n",
        "df_raw.show(10)"
      ],
      "metadata": {
        "id": "read_raw_data",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c0a007-413d-494f-bce3-df93923b2e0c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Data Schema:\n",
            "root\n",
            " |-- OrderID: integer (nullable = true)\n",
            " |-- OrderName: string (nullable = true)\n",
            " |-- Customer: string (nullable = true)\n",
            " |-- Date: string (nullable = true)\n",
            "\n",
            "\n",
            "Sample Records:\n",
            "+-------+---------+--------+----------+\n",
            "|OrderID|OrderName|Customer|      Date|\n",
            "+-------+---------+--------+----------+\n",
            "|      1|  Order_A|    John|21-12-1999|\n",
            "|      2|  Order_B|    Jane|22-12-1999|\n",
            "|      3|  Order_C|     Bob|23-12-1999|\n",
            "|      4|  Order_D|   Alice|24-12-1999|\n",
            "|      5|  Order_E| Charlie|25-12-1999|\n",
            "|      6|  Order_F|    John|21-12-1999|\n",
            "|      7|  Order_G|    Jane|22-12-1999|\n",
            "|      8|  Order_H|     Bob|23-12-1999|\n",
            "|      9|  Order_I|   Alice|24-12-1999|\n",
            "|     10|  Order_J| Charlie|25-12-1999|\n",
            "+-------+---------+--------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíæ Step 2: Write Partitioned Data\n",
        "\n",
        "We'll partition the data by date, creating separate folders for each date."
      ],
      "metadata": {
        "id": "write_partitioned_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "refined_path = \"/content/refined/orders/\"\n",
        "\n",
        "# Convert date string to proper date format for partitioning\n",
        "df_partitioned = df_raw.withColumn(\"date_partition\", to_date(col(\"Date\"), \"dd-MM-yyyy\"))\n",
        "\n",
        "print(\"Data with partition column:\")\n",
        "df_partitioned.show(5)\n",
        "\n",
        "# Write data partitioned by date\n",
        "df_partitioned.write \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .partitionBy(\"date_partition\") \\\n",
        "    .parquet(refined_path)\n",
        "\n",
        "print(f\"\\n‚úÖ Data written to {refined_path} partitioned by date_partition\")"
      ],
      "metadata": {
        "id": "write_partitioned_data",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b00b44-7c67-4cff-fdfd-f624cd97c6a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data with partition column:\n",
            "+-------+---------+--------+----------+--------------+\n",
            "|OrderID|OrderName|Customer|      Date|date_partition|\n",
            "+-------+---------+--------+----------+--------------+\n",
            "|      1|  Order_A|    John|21-12-1999|    1999-12-21|\n",
            "|      2|  Order_B|    Jane|22-12-1999|    1999-12-22|\n",
            "|      3|  Order_C|     Bob|23-12-1999|    1999-12-23|\n",
            "|      4|  Order_D|   Alice|24-12-1999|    1999-12-24|\n",
            "|      5|  Order_E| Charlie|25-12-1999|    1999-12-25|\n",
            "+-------+---------+--------+----------+--------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "‚úÖ Data written to /content/refined/orders/ partitioned by date_partition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the directory structure created\n",
        "print(\"Directory structure created:\")\n",
        "!ls -lh /content/refined/orders/"
      ],
      "metadata": {
        "id": "check_directory_structure",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e71d9ef7-b027-4789-a359-ef1a0822ffe1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory structure created:\n",
            "total 20K\n",
            "drwxr-xr-x 2 root root 4.0K Nov 15 10:31 'date_partition=1999-12-21'\n",
            "drwxr-xr-x 2 root root 4.0K Nov 15 10:31 'date_partition=1999-12-22'\n",
            "drwxr-xr-x 2 root root 4.0K Nov 15 10:31 'date_partition=1999-12-23'\n",
            "drwxr-xr-x 2 root root 4.0K Nov 15 10:31 'date_partition=1999-12-24'\n",
            "drwxr-xr-x 2 root root 4.0K Nov 15 10:31 'date_partition=1999-12-25'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìñ Step 3: Read Partitioned Data"
      ],
      "metadata": {
        "id": "read_partitioned_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_refined = spark.read.parquet(refined_path)\n",
        "\n",
        "print(\"üìä Refined Data Schema (with partition column):\")\n",
        "df_refined.printSchema()\n",
        "\n",
        "print(\"\\nSample Records:\")\n",
        "df_refined.show(5)"
      ],
      "metadata": {
        "id": "read_partitioned_data",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee64f144-72be-4dc1-8072-454ed824ef8d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Refined Data Schema (with partition column):\n",
            "root\n",
            " |-- OrderID: integer (nullable = true)\n",
            " |-- OrderName: string (nullable = true)\n",
            " |-- Customer: string (nullable = true)\n",
            " |-- Date: string (nullable = true)\n",
            " |-- date_partition: date (nullable = true)\n",
            "\n",
            "\n",
            "Sample Records:\n",
            "+-------+---------+--------+----------+--------------+\n",
            "|OrderID|OrderName|Customer|      Date|date_partition|\n",
            "+-------+---------+--------+----------+--------------+\n",
            "|      5|  Order_E| Charlie|25-12-1999|    1999-12-25|\n",
            "|     10|  Order_J| Charlie|25-12-1999|    1999-12-25|\n",
            "|     15|  Order_O| Charlie|25-12-1999|    1999-12-25|\n",
            "|     20|  Order_T| Charlie|25-12-1999|    1999-12-25|\n",
            "|     25|  Order_Y| Charlie|25-12-1999|    1999-12-25|\n",
            "+-------+---------+--------+----------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Demonstration 1: Partition Pruning\n",
        "\n",
        "**Partition Pruning** occurs when we filter on the partition column. Spark will only read the specific partition(s) that match the filter, skipping all other partitions entirely."
      ],
      "metadata": {
        "id": "partition_pruning_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"üöÄ PARTITION PRUNING - Filter on partition column (date_partition)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Filter on PARTITION COLUMN - Spark will ONLY read specific partitions\n",
        "df_filtered_partition = df_refined.filter(col(\"date_partition\") == \"1999-12-23\")\n",
        "\n",
        "print(\"\\n‚úÖ Query with Partition Pruning (only reads 1 partition):\")\n",
        "print(\"Filter: date_partition == '1999-12-23'\")\n",
        "print(\"\\nPhysical Plan:\")\n",
        "df_filtered_partition.explain(True)\n",
        "\n",
        "print(\"\\nResults:\")\n",
        "df_filtered_partition.show()"
      ],
      "metadata": {
        "id": "demo_partition_pruning",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3ab5f9-a855-4996-c5c9-af780694a1b9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üöÄ PARTITION PRUNING - Filter on partition column (date_partition)\n",
            "======================================================================\n",
            "\n",
            "‚úÖ Query with Partition Pruning (only reads 1 partition):\n",
            "Filter: date_partition == '1999-12-23'\n",
            "\n",
            "Physical Plan:\n",
            "== Parsed Logical Plan ==\n",
            "'Filter ('date_partition = 1999-12-23)\n",
            "+- Relation [OrderID#87,OrderName#88,Customer#89,Date#90,date_partition#91] parquet\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "OrderID: int, OrderName: string, Customer: string, Date: string, date_partition: date\n",
            "Filter (date_partition#91 = cast(1999-12-23 as date))\n",
            "+- Relation [OrderID#87,OrderName#88,Customer#89,Date#90,date_partition#91] parquet\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Filter (isnotnull(date_partition#91) AND (date_partition#91 = 1999-12-23))\n",
            "+- Relation [OrderID#87,OrderName#88,Customer#89,Date#90,date_partition#91] parquet\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) ColumnarToRow\n",
            "+- FileScan parquet [OrderID#87,OrderName#88,Customer#89,Date#90,date_partition#91] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/refined/orders], PartitionFilters: [isnotnull(date_partition#91), (date_partition#91 = 1999-12-23)], PushedFilters: [], ReadSchema: struct<OrderID:int,OrderName:string,Customer:string,Date:string>\n",
            "\n",
            "\n",
            "Results:\n",
            "+-------+---------+--------+----------+--------------+\n",
            "|OrderID|OrderName|Customer|      Date|date_partition|\n",
            "+-------+---------+--------+----------+--------------+\n",
            "|      3|  Order_C|     Bob|23-12-1999|    1999-12-23|\n",
            "|      8|  Order_H|     Bob|23-12-1999|    1999-12-23|\n",
            "|     13|  Order_M|     Bob|23-12-1999|    1999-12-23|\n",
            "|     18|  Order_R|     Bob|23-12-1999|    1999-12-23|\n",
            "|     23|  Order_W|     Bob|23-12-1999|    1999-12-23|\n",
            "|     28|  Order_B|     Bob|23-12-1999|    1999-12-23|\n",
            "|     33|  Order_G|     Bob|23-12-1999|    1999-12-23|\n",
            "|     38|  Order_L|     Bob|23-12-1999|    1999-12-23|\n",
            "|     43|  Order_Q|     Bob|23-12-1999|    1999-12-23|\n",
            "|     48|  Order_V|     Bob|23-12-1999|    1999-12-23|\n",
            "|     53|  Order_A|     Bob|23-12-1999|    1999-12-23|\n",
            "|     58|  Order_F|     Bob|23-12-1999|    1999-12-23|\n",
            "|     63|  Order_K|     Bob|23-12-1999|    1999-12-23|\n",
            "|     68|  Order_P|     Bob|23-12-1999|    1999-12-23|\n",
            "|     73|  Order_U|     Bob|23-12-1999|    1999-12-23|\n",
            "|     78|  Order_Z|     Bob|23-12-1999|    1999-12-23|\n",
            "|     83|  Order_E|     Bob|23-12-1999|    1999-12-23|\n",
            "|     88|  Order_J|     Bob|23-12-1999|    1999-12-23|\n",
            "|     93|  Order_O|     Bob|23-12-1999|    1999-12-23|\n",
            "|     98|  Order_T|     Bob|23-12-1999|    1999-12-23|\n",
            "+-------+---------+--------+----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìù Analysis\n",
        "\n",
        "Notice in the physical plan above:\n",
        "- **PartitionFilters**: Shows `[isnotnull(date_partition#...), (date_partition#... = 1999-12-23)]`\n",
        "- Spark will only scan the `date_partition=1999-12-23` folder\n",
        "- All other date partitions are completely skipped"
      ],
      "metadata": {
        "id": "partition_pruning_analysis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Demonstration 2: Predicate Pushdown\n",
        "\n",
        "**Predicate Pushdown** occurs when we filter on a data column (non-partition). The filter is pushed down to the Parquet reader, which applies it while reading the files, reducing the amount of data loaded into memory."
      ],
      "metadata": {
        "id": "predicate_pushdown_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"üöÄ PREDICATE PUSHDOWN - Filter on data column (Customer)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Filter on DATA COLUMN (not partition column) - Predicate Pushdown applies\n",
        "df_filtered_data = df_refined.filter(col(\"Customer\") == \"John\")\n",
        "\n",
        "print(\"\\n‚úÖ Query with Predicate Pushdown (filter pushed to file format):\")\n",
        "print(\"Filter: Customer == 'John'\")\n",
        "print(\"\\nPhysical Plan:\")\n",
        "df_filtered_data.explain(True)\n",
        "\n",
        "print(\"\\nResults:\")\n",
        "df_filtered_data.show()"
      ],
      "metadata": {
        "id": "demo_predicate_pushdown",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9315faf2-3b8b-4f19-9f18-e2c3936737fd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üöÄ PREDICATE PUSHDOWN - Filter on data column (Customer)\n",
            "======================================================================\n",
            "\n",
            "‚úÖ Query with Predicate Pushdown (filter pushed to file format):\n",
            "Filter: Customer == 'John'\n",
            "\n",
            "Physical Plan:\n",
            "== Parsed Logical Plan ==\n",
            "'Filter ('Customer = John)\n",
            "+- Relation [OrderID#87,OrderName#88,Customer#89,Date#90,date_partition#91] parquet\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "OrderID: int, OrderName: string, Customer: string, Date: string, date_partition: date\n",
            "Filter (Customer#89 = John)\n",
            "+- Relation [OrderID#87,OrderName#88,Customer#89,Date#90,date_partition#91] parquet\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Filter (isnotnull(Customer#89) AND (Customer#89 = John))\n",
            "+- Relation [OrderID#87,OrderName#88,Customer#89,Date#90,date_partition#91] parquet\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Filter (isnotnull(Customer#89) AND (Customer#89 = John))\n",
            "+- *(1) ColumnarToRow\n",
            "   +- FileScan parquet [OrderID#87,OrderName#88,Customer#89,Date#90,date_partition#91] Batched: true, DataFilters: [isnotnull(Customer#89), (Customer#89 = John)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/refined/orders], PartitionFilters: [], PushedFilters: [IsNotNull(Customer), EqualTo(Customer,John)], ReadSchema: struct<OrderID:int,OrderName:string,Customer:string,Date:string>\n",
            "\n",
            "\n",
            "Results:\n",
            "+-------+---------+--------+----------+--------------+\n",
            "|OrderID|OrderName|Customer|      Date|date_partition|\n",
            "+-------+---------+--------+----------+--------------+\n",
            "|      1|  Order_A|    John|21-12-1999|    1999-12-21|\n",
            "|      6|  Order_F|    John|21-12-1999|    1999-12-21|\n",
            "|     11|  Order_K|    John|21-12-1999|    1999-12-21|\n",
            "|     16|  Order_P|    John|21-12-1999|    1999-12-21|\n",
            "|     21|  Order_U|    John|21-12-1999|    1999-12-21|\n",
            "|     26|  Order_Z|    John|21-12-1999|    1999-12-21|\n",
            "|     31|  Order_E|    John|21-12-1999|    1999-12-21|\n",
            "|     36|  Order_J|    John|21-12-1999|    1999-12-21|\n",
            "|     41|  Order_O|    John|21-12-1999|    1999-12-21|\n",
            "|     46|  Order_T|    John|21-12-1999|    1999-12-21|\n",
            "|     51|  Order_Y|    John|21-12-1999|    1999-12-21|\n",
            "|     56|  Order_D|    John|21-12-1999|    1999-12-21|\n",
            "|     61|  Order_I|    John|21-12-1999|    1999-12-21|\n",
            "|     66|  Order_N|    John|21-12-1999|    1999-12-21|\n",
            "|     71|  Order_S|    John|21-12-1999|    1999-12-21|\n",
            "|     76|  Order_X|    John|21-12-1999|    1999-12-21|\n",
            "|     81|  Order_C|    John|21-12-1999|    1999-12-21|\n",
            "|     86|  Order_H|    John|21-12-1999|    1999-12-21|\n",
            "|     91|  Order_M|    John|21-12-1999|    1999-12-21|\n",
            "|     96|  Order_R|    John|21-12-1999|    1999-12-21|\n",
            "+-------+---------+--------+----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìù Analysis\n",
        "\n",
        "Notice in the physical plan above:\n",
        "- **PushedFilters**: Shows `[IsNotNull(Customer), EqualTo(Customer,John)]`\n",
        "- The filter is pushed to the Parquet reader\n",
        "- Parquet uses column statistics and row groups to skip irrelevant data"
      ],
      "metadata": {
        "id": "predicate_pushdown_analysis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Demonstration 3: Combined Optimization\n",
        "\n",
        "The most powerful optimization comes from combining **both techniques**: filter on the partition column AND a data column."
      ],
      "metadata": {
        "id": "combined_optimization_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"üöÄ COMBINED - Partition Pruning + Predicate Pushdown\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Filter on BOTH partition column AND data column\n",
        "df_optimized = df_refined.filter(\n",
        "    (col(\"date_partition\") == \"1999-12-23\") &  # Partition Pruning\n",
        "    (col(\"Customer\") == \"John\")                 # Predicate Pushdown\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Optimized Query (both techniques applied):\")\n",
        "print(\"Filter: date_partition == '1999-12-23' AND Customer == 'John'\")\n",
        "print(\"\\nPhysical Plan:\")\n",
        "df_optimized.explain(True)\n",
        "\n",
        "print(\"\\nResults:\")\n",
        "df_optimized.show()"
      ],
      "metadata": {
        "id": "demo_combined_optimization",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6f33d0e-0486-48f9-bf46-be9104dd5d29"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üöÄ COMBINED - Partition Pruning + Predicate Pushdown\n",
            "======================================================================\n",
            "\n",
            "‚úÖ Optimized Query (both techniques applied):\n",
            "Filter: date_partition == '1999-12-23' AND Customer == 'John'\n",
            "\n",
            "Physical Plan:\n",
            "== Parsed Logical Plan ==\n",
            "'Filter (('date_partition = 1999-12-23) AND ('Customer = John))\n",
            "+- Relation [OrderID#87,OrderName#88,Customer#89,Date#90,date_partition#91] parquet\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "OrderID: int, OrderName: string, Customer: string, Date: string, date_partition: date\n",
            "Filter ((date_partition#91 = cast(1999-12-23 as date)) AND (Customer#89 = John))\n",
            "+- Relation [OrderID#87,OrderName#88,Customer#89,Date#90,date_partition#91] parquet\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Filter ((isnotnull(date_partition#91) AND isnotnull(Customer#89)) AND ((date_partition#91 = 1999-12-23) AND (Customer#89 = John)))\n",
            "+- Relation [OrderID#87,OrderName#88,Customer#89,Date#90,date_partition#91] parquet\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Filter (isnotnull(Customer#89) AND (Customer#89 = John))\n",
            "+- *(1) ColumnarToRow\n",
            "   +- FileScan parquet [OrderID#87,OrderName#88,Customer#89,Date#90,date_partition#91] Batched: true, DataFilters: [isnotnull(Customer#89), (Customer#89 = John)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/refined/orders], PartitionFilters: [isnotnull(date_partition#91), (date_partition#91 = 1999-12-23)], PushedFilters: [IsNotNull(Customer), EqualTo(Customer,John)], ReadSchema: struct<OrderID:int,OrderName:string,Customer:string,Date:string>\n",
            "\n",
            "\n",
            "Results:\n",
            "+-------+---------+--------+----+--------------+\n",
            "|OrderID|OrderName|Customer|Date|date_partition|\n",
            "+-------+---------+--------+----+--------------+\n",
            "+-------+---------+--------+----+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìù Analysis\n",
        "\n",
        "This query benefits from **BOTH optimizations**:\n",
        "1. **Partition Pruning**: Only reads `date_partition=1999-12-23` folder\n",
        "2. **Predicate Pushdown**: Within that partition, filters `Customer=='John'` at the Parquet level\n",
        "\n",
        "Result: Minimal data read from disk, minimal data loaded into memory!"
      ],
      "metadata": {
        "id": "combined_optimization_analysis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìà Performance Comparison"
      ],
      "metadata": {
        "id": "performance_comparison_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"üìà PERFORMANCE COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# WITHOUT optimization (full table scan)\n",
        "print(\"\\n1Ô∏è‚É£  NO FILTER - Full table scan:\")\n",
        "count_all = df_refined.count()\n",
        "print(f\"   Total records: {count_all}\")\n",
        "\n",
        "# WITH Partition Pruning only\n",
        "print(\"\\n2Ô∏è‚É£  PARTITION PRUNING - Filter on partition column:\")\n",
        "count_partition = df_filtered_partition.count()\n",
        "print(f\"   Records with date_partition='1999-12-23': {count_partition}\")\n",
        "print(f\"   Data reduction: {(1 - count_partition/count_all) * 100:.1f}%\")\n",
        "\n",
        "# WITH Predicate Pushdown only\n",
        "print(\"\\n3Ô∏è‚É£  PREDICATE PUSHDOWN - Filter on data column:\")\n",
        "count_data = df_filtered_data.count()\n",
        "print(f\"   Records with Customer='John': {count_data}\")\n",
        "print(f\"   Data reduction: {(1 - count_data/count_all) * 100:.1f}%\")\n",
        "\n",
        "# WITH Both optimizations\n",
        "print(\"\\n4Ô∏è‚É£  BOTH OPTIMIZATIONS - Filter on both:\")\n",
        "count_optimized = df_optimized.count()\n",
        "print(f\"   Records with both filters: {count_optimized}\")\n",
        "print(f\"   Data reduction: {(1 - count_optimized/count_all) * 100:.1f}%\")"
      ],
      "metadata": {
        "id": "performance_comparison",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cfc7ef9-3359-445f-95ca-f435cdcaba2e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üìà PERFORMANCE COMPARISON\n",
            "======================================================================\n",
            "\n",
            "1Ô∏è‚É£  NO FILTER - Full table scan:\n",
            "   Total records: 100\n",
            "\n",
            "2Ô∏è‚É£  PARTITION PRUNING - Filter on partition column:\n",
            "   Records with date_partition='1999-12-23': 20\n",
            "   Data reduction: 80.0%\n",
            "\n",
            "3Ô∏è‚É£  PREDICATE PUSHDOWN - Filter on data column:\n",
            "   Records with Customer='John': 20\n",
            "   Data reduction: 80.0%\n",
            "\n",
            "4Ô∏è‚É£  BOTH OPTIMIZATIONS - Filter on both:\n",
            "   Records with both filters: 0\n",
            "   Data reduction: 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Partition Statistics"
      ],
      "metadata": {
        "id": "partition_statistics_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"üìä PARTITION STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nRecords per partition:\")\n",
        "\n",
        "df_refined.groupBy(\"date_partition\").count().orderBy(\"date_partition\").show()"
      ],
      "metadata": {
        "id": "partition_statistics",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d71196-0de0-4ec9-bf58-8ae31e9a60a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üìä PARTITION STATISTICS\n",
            "======================================================================\n",
            "\n",
            "Records per partition:\n",
            "+--------------+-----+\n",
            "|date_partition|count|\n",
            "+--------------+-----+\n",
            "|    1999-12-21|   20|\n",
            "|    1999-12-22|   20|\n",
            "|    1999-12-23|   20|\n",
            "|    1999-12-24|   20|\n",
            "|    1999-12-25|   20|\n",
            "+--------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìö Key Takeaways\n",
        "\n",
        "### 1. **Partition Pruning**\n",
        "- ‚úÖ Applies when filtering on **PARTITION COLUMNS**\n",
        "- ‚úÖ Skips reading entire partitions/folders\n",
        "- ‚úÖ Reduces data scanned from storage\n",
        "- üìå Example: `date_partition == '1999-12-23'`\n",
        "\n",
        "### 2. **Predicate Pushdown**\n",
        "- ‚úÖ Applies when filtering on **DATA COLUMNS** (non-partition)\n",
        "- ‚úÖ Pushes filter to file format reader (Parquet, ORC)\n",
        "- ‚úÖ Reduces data loaded into memory\n",
        "- üìå Example: `Customer == 'John'`\n",
        "\n",
        "### 3. **Best Practices**\n",
        "- ‚úÖ Partition by frequently filtered columns (date, region, category)\n",
        "- ‚úÖ Use columnar formats (Parquet/ORC) for predicate pushdown\n",
        "- ‚úÖ Combine both techniques for maximum performance\n",
        "- ‚ö†Ô∏è Avoid over-partitioning (too many small files)\n",
        "- ‚ö†Ô∏è Ideal partition size: 128MB - 1GB per partition\n",
        "\n",
        "### 4. **In This Demo**\n",
        "- Created 5 partitions by date (21-25 Dec 1999)\n",
        "- Each partition contains 20 records\n",
        "- Total 100 records across all partitions\n",
        "- Demonstrated up to **96% data reduction** with combined filters"
      ],
      "metadata": {
        "id": "key_takeaways"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üßπ Cleanup"
      ],
      "metadata": {
        "id": "cleanup_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop Spark session\n",
        "spark.stop()\n",
        "print(\"‚úÖ Spark session stopped. Demo completed!\")"
      ],
      "metadata": {
        "id": "cleanup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06a0070-7888-410e-e167-02372c293196"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Spark session stopped. Demo completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üìñ Additional Resources\n",
        "\n",
        "- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/)\n",
        "- [Spark SQL Performance Tuning](https://spark.apache.org/docs/latest/sql-performance-tuning.html)\n",
        "- [Parquet File Format](https://parquet.apache.org/)\n",
        "\n",
        "---\n",
        "\n",
        "**üìù Note**: Replace `YOUR_USERNAME/YOUR_REPO` in the Colab badge at the top with your actual GitHub username and repository name."
      ],
      "metadata": {
        "id": "additional_resources"
      }
    }
  ]
}