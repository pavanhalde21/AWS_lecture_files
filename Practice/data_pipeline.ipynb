{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4598e4ff",
   "metadata": {},
   "source": [
    "Step 1: Create AWS Session and clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efba428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "aws_session = boto3.Session(\n",
    "    aws_access_key_id='',\n",
    "    aws_secret_access_key='',\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "cfg = Config(retries={\"max_attempts\": 10, \"mode\": \"standard\"}, read_timeout=60, connect_timeout=10)\n",
    "\n",
    "s3_client = aws_session.client('s3')\n",
    "glue_client = aws_session.client('glue')\n",
    "\n",
    "athena  = aws_session.client(\"athena\", config=cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb3b516",
   "metadata": {},
   "source": [
    "Step 2: Extract the data from Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aae12ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running query: SELECT * FROM olist_brazil_e_commerce.customers\n",
      "/var/folders/19/6l7wlwds1jv0rjylrz6p14yc0000gn/T/ipykernel_56279/2962071395.py:36: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "INFO:root:‚úÖ Uploaded to: s3://golu-aws-project-bucket/raw/customers/customers.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://golu-aws-project-bucket/raw/customers/customers.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import logging\n",
    "\n",
    "def extract_postgres_to_s3(\n",
    "        table_name,\n",
    "        schema=\"public\",\n",
    "        where_clause=None,\n",
    "        partition_date=None,\n",
    "        pg_config=None\n",
    "    ):\n",
    "\n",
    "    # Default configs\n",
    "    pg_config = pg_config or {\n",
    "        'host': 'localhost',\n",
    "        'port': '5432',\n",
    "        'user': 'postgres',\n",
    "        'password': '4518',\n",
    "        'database': 'kaggle_practice'\n",
    "    }\n",
    "\n",
    "    bucket='golu-aws-project-bucket'\n",
    "\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    try:\n",
    "        conn = psycopg2.connect(**pg_config)\n",
    "        query = f\"SELECT * FROM {schema}.{table_name}\"\n",
    "        if where_clause:\n",
    "            query += f\" WHERE {where_clause}\"\n",
    "\n",
    "        logging.info(f\"Running query: {query}\")\n",
    "\n",
    "        df = pd.read_sql(query, conn)\n",
    "        if df.empty:\n",
    "            logging.warning(\"No data found.\")\n",
    "            return None\n",
    "\n",
    "\n",
    "        # S3 key path\n",
    "        key = f\"raw/{table_name}\"\n",
    "        if partition_date:\n",
    "            key += f\"/dt={partition_date}\"\n",
    "        key += f\"/{table_name}.csv\"\n",
    "\n",
    "        csv_buffer = StringIO()\n",
    "        df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "        s3_client.put_object(\n",
    "            Bucket=bucket,\n",
    "            Key=key,\n",
    "            Body=csv_buffer.getvalue()\n",
    "        )\n",
    "\n",
    "        s3_uri = f\"s3://{bucket}/{key}\"\n",
    "        logging.info(f\"‚úÖ Uploaded to: {s3_uri}\")\n",
    "        return s3_uri\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"‚ùå Failed: {e}\")\n",
    "        raise\n",
    "\n",
    "extract_postgres_to_s3(\"customers\", \"olist_brazil_e_commerce\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a8ffae",
   "metadata": {},
   "source": [
    "Step 3: Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a5c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Glue Crawler\n",
    "\n",
    "crawler_name = \"crawler_03\"\n",
    "role = \"arn:aws:iam::180294202865:role/glue_role_to_give_full_access_to_s3\"\n",
    "database_name = \"mydb_01\"\n",
    "s3_target_path = f\"s3://golu-aws-project-bucket/raw/customers/\"  # adjust path as needed\n",
    "table_prefix = \"raw_\"\n",
    "\n",
    "\n",
    "try:\n",
    "    response = glue_client.create_crawler(\n",
    "        Name=crawler_name,\n",
    "        Role=role,\n",
    "        DatabaseName=database_name,\n",
    "        Description=\"Crawler created via boto3 from Jupyter notebook\",\n",
    "        Targets={\n",
    "            \"S3Targets\": [\n",
    "                {\"Path\": s3_target_path}\n",
    "            ]\n",
    "        },\n",
    "        TablePrefix=table_prefix,\n",
    "        Classifiers=[],\n",
    "        RecrawlPolicy={\"RecrawlBehavior\": \"CRAWL_EVERYTHING\"},\n",
    "        SchemaChangePolicy={\n",
    "            \"UpdateBehavior\": \"UPDATE_IN_DATABASE\",\n",
    "            \"DeleteBehavior\": \"DEPRECATE_IN_DATABASE\"\n",
    "        },\n",
    "        Configuration='{\"Version\":1.0,\"CreatePartitionIndex\":true}'\n",
    "    )\n",
    "    print(f\"Crawler '{crawler_name}' created. Response HTTPStatusCode: {response.get('ResponseMetadata', {}).get('HTTPStatusCode')}\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to create crawler:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4e754ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawler Name: CRAWLER_04, Crawler State: READY\n",
      "Crawler Name: crawler_01, Crawler State: READY\n",
      "Crawler Name: crawler_02, Crawler State: READY\n",
      "Crawler Name: crawler_03, Crawler State: STOPPING\n"
     ]
    }
   ],
   "source": [
    "# List Crawlers ::\n",
    "response = glue_client.get_crawlers()\n",
    "crawlers = response['Crawlers']\n",
    "for crawler in crawlers:\n",
    "    print(f\"Crawler Name: {crawler['Name']}, Crawler State: {crawler['State']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9efe37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '909f9d4e-68c9-4714-9919-064fc941a933', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 04 Nov 2025 18:11:12 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '2', 'connection': 'keep-alive', 'x-amzn-requestid': '909f9d4e-68c9-4714-9919-064fc941a933', 'cache-control': 'no-cache'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Start the crawler\n",
    "response = glue_client.start_crawler(Name='crawler_03')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79d259a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Crawler State: RUNNING\n"
     ]
    }
   ],
   "source": [
    "# Get status of the crawler\n",
    "state = glue_client.get_crawler(Name=crawler_name)[\"Crawler\"][\"State\"]\n",
    "print(f\"Current Crawler State: {state}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b0c1d7",
   "metadata": {},
   "source": [
    "Step 4: Glue Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "874bf876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Glue Job Script to S3 \n",
    "s3_client.upload_file(r\"/Users/pavanhalde/Downloads/glue_job_05.py\", 'golu-aws-project-bucket', 'scripts/glue_job_05.py')\n",
    "\n",
    "# Note: In industry we use CI/CD pipelines to automate such tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8da85c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Glue Job \n",
    "response = glue_client.create_job(\n",
    "    Name=\"glue_job_05\",\n",
    "    Role=\"arn:aws:iam::180294202865:role/glue_role_to_give_full_access_to_s3\",\n",
    "    Command={\n",
    "        'Name': 'glueetl',\n",
    "        'ScriptLocation': \"s3://golu-aws-project-bucket/scripts/glue_job_05.py\"\n",
    "    },\n",
    "    GlueVersion='4.0',\n",
    "    WorkerType='G.1X',\n",
    "    NumberOfWorkers=2,\n",
    "    ExecutionProperty={\n",
    "        'MaxConcurrentRuns': 1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dc6dc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Name: glue_job_01\n",
      "Job Name: glue_job_02\n",
      "Job Name: glue_job_03\n",
      "Job Name: glue_job_04\n",
      "Job Name: glue_job_05\n"
     ]
    }
   ],
   "source": [
    "# Listing jobs in account:\n",
    "response = glue_client.get_jobs()\n",
    "jobs=response['Jobs']\n",
    "for job in jobs:\n",
    "    print(f\"Job Name: {job['Name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64a37ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job run started with ID: jr_a95c6dc727d516ba5bbddf15684e532e6d7583d7f68ba3265461774d9724ea72\n"
     ]
    }
   ],
   "source": [
    "# Start Job Run ::\n",
    "response = glue_client.start_job_run(JobName='glue_job_05')\n",
    "job_run_id = response['JobRunId']\n",
    "print(f\"Job run started with ID: {job_run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bbe5aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Run Status: SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "# Get Job Run::\n",
    "response = glue_client.get_job_run(JobName='glue_job_05', RunId=job_run_id)\n",
    "job_run = response['JobRun']\n",
    "print(f\"Job Run Status: {job_run['JobRunState']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47152d6f",
   "metadata": {},
   "source": [
    "Step 5: Crawler for refined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13e5bede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawler 'crawler_refined_03' created. Response HTTPStatusCode: 200\n"
     ]
    }
   ],
   "source": [
    "# Create Glue Crawler\n",
    "\n",
    "crawler_name = \"crawler_refined_03\"\n",
    "role = \"arn:aws:iam::180294202865:role/glue_role_to_give_full_access_to_s3\"\n",
    "database_name = \"mydb_01\"\n",
    "s3_target_path = f\"s3://golu-aws-project-bucket/output/brazil_e_commerce/customer_refined/\" \n",
    "table_prefix = \"refined_\"\n",
    "\n",
    "\n",
    "try:\n",
    "    response = glue_client.create_crawler(\n",
    "        Name=crawler_name,\n",
    "        Role=role,\n",
    "        DatabaseName=database_name,\n",
    "        Description=\"Crawler created via boto3 from Jupyter notebook\",\n",
    "        Targets={\n",
    "            \"S3Targets\": [\n",
    "                {\"Path\": s3_target_path}\n",
    "            ]\n",
    "        },\n",
    "        TablePrefix=table_prefix,\n",
    "        Classifiers=[],\n",
    "        RecrawlPolicy={\"RecrawlBehavior\": \"CRAWL_EVERYTHING\"},\n",
    "        SchemaChangePolicy={\n",
    "            \"UpdateBehavior\": \"UPDATE_IN_DATABASE\",\n",
    "            \"DeleteBehavior\": \"DEPRECATE_IN_DATABASE\"\n",
    "        },\n",
    "        Configuration='{\"Version\":1.0,\"CreatePartitionIndex\":true}'\n",
    "    )\n",
    "    print(f\"Crawler '{crawler_name}' created. Response HTTPStatusCode: {response.get('ResponseMetadata', {}).get('HTTPStatusCode')}\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to create crawler:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac084e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawler Name: CRAWLER_04, Crawler State: READY\n",
      "Crawler Name: crawler_01, Crawler State: READY\n",
      "Crawler Name: crawler_02, Crawler State: READY\n",
      "Crawler Name: crawler_03, Crawler State: READY\n",
      "Crawler Name: crawler_refined_03, Crawler State: READY\n"
     ]
    }
   ],
   "source": [
    "# List Crawlers ::\n",
    "response = glue_client.get_crawlers()\n",
    "crawlers = response['Crawlers']\n",
    "for crawler in crawlers:\n",
    "    print(f\"Crawler Name: {crawler['Name']}, Crawler State: {crawler['State']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44a52694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '1a2e7264-617f-43f5-8238-e055d745a0b3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 04 Nov 2025 18:33:20 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '2', 'connection': 'keep-alive', 'x-amzn-requestid': '1a2e7264-617f-43f5-8238-e055d745a0b3', 'cache-control': 'no-cache'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Start the crawler\n",
    "response = glue_client.start_crawler(Name='crawler_refined_03')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1aeafd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Crawler State: RUNNING\n"
     ]
    }
   ],
   "source": [
    "# Get status of the crawler\n",
    "state = glue_client.get_crawler(Name=crawler_name)[\"Crawler\"][\"State\"]\n",
    "print(f\"Current Crawler State: {state}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bdb0fb",
   "metadata": {},
   "source": [
    "Step 6: Validation through Athena "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cacb3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîç VALIDATING GLUE JOB TRANSFORMATIONS\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "\n",
    "# Configuration\n",
    "WORKGROUP       = \"primary\"\n",
    "OUTPUT_LOCATION = \"s3://golu-aws-project-bucket/athena-results/\"  # For Athena query results only\n",
    "DATABASE        = \"mydb_01\"  # Your Glue database name\n",
    "RAW_TABLE       = \"raw_customers\"  # Original raw table\n",
    "REFINED_TABLE   = \"refined_customer_refined\"  # Table created by crawler (with prefix)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üîç VALIDATING GLUE JOB TRANSFORMATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def run_athena_query(sql, description):\n",
    "    \"\"\"Helper function to run Athena query and display results\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üìä {description}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Query: {sql[:100]}...\")\n",
    "    \n",
    "    # Start query execution\n",
    "    resp = athena.start_query_execution(\n",
    "        QueryString=sql,\n",
    "        QueryExecutionContext={\"Database\": DATABASE},\n",
    "        WorkGroup=WORKGROUP,\n",
    "        ResultConfiguration={\"OutputLocation\": OUTPUT_LOCATION}\n",
    "    )\n",
    "    qid = resp[\"QueryExecutionId\"]\n",
    "    print(f\"Query ID: {qid}\")\n",
    "    \n",
    "    # Wait for completion\n",
    "    print(\"‚è≥ Waiting for query to complete...\", end=\"\")\n",
    "    while True:\n",
    "        status = athena.get_query_execution(QueryExecutionId=qid)[\"QueryExecution\"][\"Status\"][\"State\"]\n",
    "        if status in (\"SUCCEEDED\", \"FAILED\", \"CANCELLED\"):\n",
    "            break\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    print(f\"\\nStatus: {status}\")\n",
    "    \n",
    "    if status != \"SUCCEEDED\":\n",
    "        detail = athena.get_query_execution(QueryExecutionId=qid)[\"QueryExecution\"][\"Status\"]\n",
    "        print(f\"‚ùå Query failed: {detail}\")\n",
    "        return None\n",
    "    \n",
    "    # Get results\n",
    "    results = athena.get_query_results(QueryExecutionId=qid)\n",
    "    headers = [c.get(\"VarCharValue\", \"\") for c in results[\"ResultSet\"][\"Rows\"][0][\"Data\"]]\n",
    "    rows = [[c.get(\"VarCharValue\", None) for c in r[\"Data\"]] \n",
    "            for r in results[\"ResultSet\"][\"Rows\"][1:]]\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \" | \".join(headers))\n",
    "    print(\"-\" * 60)\n",
    "    for row in rows:\n",
    "        print(\" | \".join(str(cell) if cell else \"NULL\" for cell in row))\n",
    "    print(f\"\\n‚úÖ Rows returned: {len(rows)}\")\n",
    "    \n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60a59376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä Validation 1: Check Uppercase Transformation\n",
      "============================================================\n",
      "Query: \n",
      "SELECT \n",
      "    CASE \n",
      "        WHEN customer_city = UPPER(customer_city) THEN 'PASS - All Uppercase'\n",
      "   ...\n",
      "Query ID: 750d312c-7413-40df-ac17-697b4edd20d8\n",
      "‚è≥ Waiting for query to complete....\n",
      "Status: SUCCEEDED\n",
      "\n",
      "uppercase_validation | count\n",
      "------------------------------------------------------------\n",
      "PASS - All Uppercase | 41746\n",
      "\n",
      "‚úÖ Rows returned: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['PASS - All Uppercase', '41746']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# VALIDATION 1: Check if customer_city is UPPERCASE\n",
    "# ============================================================\n",
    "sql_uppercase_check = f\"\"\"\n",
    "SELECT \n",
    "    CASE \n",
    "        WHEN customer_city = UPPER(customer_city) THEN 'PASS - All Uppercase'\n",
    "        ELSE 'FAIL - Not Uppercase'\n",
    "    END AS uppercase_validation,\n",
    "    COUNT(*) AS count\n",
    "FROM {DATABASE}.{REFINED_TABLE}\n",
    "GROUP BY 1;\n",
    "\"\"\"\n",
    "run_athena_query(sql_uppercase_check, \"Validation 1: Check Uppercase Transformation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb5060d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä Validation 2: Verify State Filter (Should be SP only)\n",
      "============================================================\n",
      "Query: \n",
      "SELECT \n",
      "    customer_state,\n",
      "    COUNT(*) AS count\n",
      "FROM mydb_01.refined_customer_refined\n",
      "GROUP BY cu...\n",
      "Query ID: 465d56d4-02be-477c-8a9e-b5e7bc97e132\n",
      "‚è≥ Waiting for query to complete....\n",
      "Status: SUCCEEDED\n",
      "\n",
      "customer_state | count\n",
      "------------------------------------------------------------\n",
      "SP | 41746\n",
      "\n",
      "‚úÖ Rows returned: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['SP', '41746']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# VALIDATION 2: Verify only SP state exists\n",
    "# ============================================================\n",
    "sql_state_check = f\"\"\"\n",
    "SELECT \n",
    "    customer_state,\n",
    "    COUNT(*) AS count\n",
    "FROM {DATABASE}.{REFINED_TABLE}\n",
    "GROUP BY customer_state\n",
    "ORDER BY count DESC;\n",
    "\"\"\"\n",
    "run_athena_query(sql_state_check, \"Validation 2: Verify State Filter (Should be SP only)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "411b387f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä Validation 3: Check Dropped Columns\n",
      "============================================================\n",
      "Query: Fetching table schema...\n",
      "\n",
      "Columns in refined table:\n",
      "  1. customer_id\n",
      "  2. customer_zip_code_prefix\n",
      "  3. customer_city\n",
      "  4. customer_state\n",
      "\n",
      "‚úÖ PASS: customer_unique_id column was successfully dropped!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# VALIDATION 3: Check if customer_unique_id column was dropped\n",
    "# ============================================================\n",
    "sql_column_check = f\"\"\"\n",
    "SELECT * \n",
    "FROM {DATABASE}.{REFINED_TABLE} \n",
    "LIMIT 1;\n",
    "\"\"\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üìä Validation 3: Check Dropped Columns\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"Query: Fetching table schema...\")\n",
    "\n",
    "resp = athena.start_query_execution(\n",
    "    QueryString=sql_column_check,\n",
    "    QueryExecutionContext={\"Database\": DATABASE},\n",
    "    WorkGroup=WORKGROUP,\n",
    "    ResultConfiguration={\"OutputLocation\": OUTPUT_LOCATION}\n",
    ")\n",
    "qid = resp[\"QueryExecutionId\"]\n",
    "\n",
    "# Wait for completion\n",
    "while True:\n",
    "    status = athena.get_query_execution(QueryExecutionId=qid)[\"QueryExecution\"][\"Status\"][\"State\"]\n",
    "    if status in (\"SUCCEEDED\", \"FAILED\", \"CANCELLED\"):\n",
    "        break\n",
    "    time.sleep(2)\n",
    "\n",
    "if status == \"SUCCEEDED\":\n",
    "    results = athena.get_query_results(QueryExecutionId=qid)\n",
    "    headers = [c.get(\"VarCharValue\", \"\") for c in results[\"ResultSet\"][\"Rows\"][0][\"Data\"]]\n",
    "    print(\"\\nColumns in refined table:\")\n",
    "    for i, col in enumerate(headers, 1):\n",
    "        print(f\"  {i}. {col}\")\n",
    "    \n",
    "    if \"customer_unique_id\" in headers:\n",
    "        print(\"\\n‚ùå FAIL: customer_unique_id column still exists!\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ PASS: customer_unique_id column was successfully dropped!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "640f7b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä Validation 4: Compare Raw vs Refined Row Counts\n",
      "============================================================\n",
      "Query: \n",
      "SELECT \n",
      "    'Raw Table' AS source,\n",
      "    COUNT(*) AS row_count\n",
      "FROM mydb_01.raw_customers\n",
      "UNION ALL\n",
      "S...\n",
      "Query ID: 520f4847-135e-4832-b2bd-9d68ca3f868a\n",
      "‚è≥ Waiting for query to complete....\n",
      "Status: SUCCEEDED\n",
      "\n",
      "source | row_count\n",
      "------------------------------------------------------------\n",
      "Refined Table (SP only) | 41746\n",
      "Raw Table | 99441\n",
      "\n",
      "‚úÖ Rows returned: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Refined Table (SP only)', '41746'], ['Raw Table', '99441']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# VALIDATION 4: Compare Raw vs Refined Row Counts\n",
    "# ============================================================\n",
    "sql_compare_counts = f\"\"\"\n",
    "SELECT \n",
    "    'Raw Table' AS source,\n",
    "    COUNT(*) AS row_count\n",
    "FROM {DATABASE}.{RAW_TABLE}\n",
    "UNION ALL\n",
    "SELECT \n",
    "    'Refined Table (SP only)' AS source,\n",
    "    COUNT(*) AS row_count\n",
    "FROM {DATABASE}.{REFINED_TABLE};\n",
    "\"\"\"\n",
    "run_athena_query(sql_compare_counts, \"Validation 4: Compare Raw vs Refined Row Counts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4bad3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä Validation 5: Sample Refined Data (First 10 rows)\n",
      "============================================================\n",
      "Query: \n",
      "SELECT \n",
      "    customer_id,\n",
      "    customer_zip_code_prefix,\n",
      "    customer_city,\n",
      "    customer_state\n",
      "FROM m...\n",
      "Query ID: 532e971a-80df-4e7e-8e01-56cc20ed80d4\n",
      "‚è≥ Waiting for query to complete....\n",
      "Status: SUCCEEDED\n",
      "\n",
      "customer_id | customer_zip_code_prefix | customer_city | customer_state\n",
      "------------------------------------------------------------\n",
      "06b8999e2fba1a1fbc88172c00ba8bc7 | 14409.0 | FRANCA | SP\n",
      "18955e83d337fd6b2def6b18a428ac77 | 9790.0 | SAO BERNARDO DO CAMPO | SP\n",
      "4e7b3e00288586ebd08712fdd0374a03 | 1151.0 | SAO PAULO | SP\n",
      "b2b6027bc5c5109e529d4dc6358b12c3 | 8775.0 | MOGI DAS CRUZES | SP\n",
      "4f2d8ab171c80ec8364f7c12e35b23ad | 13056.0 | CAMPINAS | SP\n",
      "fd826e7cf63160e536e0908c76c3f441 | 4534.0 | SAO PAULO | SP\n",
      "b2d1536598b73a9abd18e0d75d92f0a3 | 18682.0 | LENCOIS PAULISTA | SP\n",
      "eabebad39a88bb6f5b52376faec28612 | 5704.0 | SAO PAULO | SP\n",
      "206f3129c0e4d7d0b9550426023f0a08 | 13412.0 | PIRACICABA | SP\n",
      "c5c61596a3b6bd0cee5766992c48a9a1 | 7124.0 | GUARULHOS | SP\n",
      "\n",
      "‚úÖ Rows returned: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['06b8999e2fba1a1fbc88172c00ba8bc7', '14409.0', 'FRANCA', 'SP'],\n",
       " ['18955e83d337fd6b2def6b18a428ac77', '9790.0', 'SAO BERNARDO DO CAMPO', 'SP'],\n",
       " ['4e7b3e00288586ebd08712fdd0374a03', '1151.0', 'SAO PAULO', 'SP'],\n",
       " ['b2b6027bc5c5109e529d4dc6358b12c3', '8775.0', 'MOGI DAS CRUZES', 'SP'],\n",
       " ['4f2d8ab171c80ec8364f7c12e35b23ad', '13056.0', 'CAMPINAS', 'SP'],\n",
       " ['fd826e7cf63160e536e0908c76c3f441', '4534.0', 'SAO PAULO', 'SP'],\n",
       " ['b2d1536598b73a9abd18e0d75d92f0a3', '18682.0', 'LENCOIS PAULISTA', 'SP'],\n",
       " ['eabebad39a88bb6f5b52376faec28612', '5704.0', 'SAO PAULO', 'SP'],\n",
       " ['206f3129c0e4d7d0b9550426023f0a08', '13412.0', 'PIRACICABA', 'SP'],\n",
       " ['c5c61596a3b6bd0cee5766992c48a9a1', '7124.0', 'GUARULHOS', 'SP']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# VALIDATION 5: Sample refined data\n",
    "# ============================================================\n",
    "sql_sample = f\"\"\"\n",
    "SELECT \n",
    "    customer_id,\n",
    "    customer_zip_code_prefix,\n",
    "    customer_city,\n",
    "    customer_state\n",
    "FROM {DATABASE}.{REFINED_TABLE}\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "run_athena_query(sql_sample, \"Validation 5: Sample Refined Data (First 10 rows)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a169aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# VALIDATION 6: Top cities in refined data\n",
    "# ============================================================\n",
    "sql_top_cities = f\"\"\"\n",
    "SELECT \n",
    "    customer_city,\n",
    "    customer_state,\n",
    "    COUNT(*) AS customer_count\n",
    "FROM {DATABASE}.{REFINED_TABLE}\n",
    "GROUP BY customer_city, customer_state\n",
    "ORDER BY customer_count DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "run_athena_query(sql_top_cities, \"Validation 6: Top 10 Cities in Refined Data\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ ALL VALIDATIONS COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nSummary of Validations:\")\n",
    "print(\"1. ‚úì Uppercase transformation on customer_city\")\n",
    "print(\"2. ‚úì State filter (SP only)\")\n",
    "print(\"3. ‚úì Column drop (customer_unique_id)\")\n",
    "print(\"4. ‚úì Row count comparison\")\n",
    "print(\"5. ‚úì Sample data inspection\")\n",
    "print(\"6. ‚úì Top cities analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704676a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703e16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d4a68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8110804e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ade3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553262e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
