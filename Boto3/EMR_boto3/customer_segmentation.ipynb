{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfc94731",
   "metadata": {},
   "source": [
    "# Problem Statement ::You have two data files stored in an Amazon S3 bucket. Your goal is to create a data processing pipeline using PySpark that reads these files from S3, performs some transformations and classify customers based on its purchases, and then submits the PySpark script as an EMR step using boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c3abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976065fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from get_creds import fetch_credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an S3 client\n",
    "emr_client=boto3.client('emr',\n",
    "    aws_access_key_id=fetch_credentials()[0],\n",
    "    aws_secret_access_key=fetch_credentials()[1],\n",
    "    region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572481b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create EMR cluster\n",
    "response = emr_client.run_job_flow(\n",
    "    Name='ds-cluster-boto3',\n",
    "    ReleaseLabel='emr-6.14.0',\n",
    "    Instances={\n",
    "        'MasterInstanceType': 'm5.xlarge',\n",
    "        'SlaveInstanceType': 'm5.xlarge',\n",
    "        'InstanceCount': 2,\n",
    "        'KeepJobFlowAliveWhenNoSteps': True,\n",
    "        'TerminationProtected': False,\n",
    "        'Ec2KeyName': 'first_keypair',\n",
    "        'EmrManagedMasterSecurityGroup': 'sg-0309ac88be23385a2',\n",
    "        'EmrManagedSlaveSecurityGroup': 'sg-0a19af4ba0a963cca',\n",
    "        'Ec2SubnetId': 'subnet-090cd51dd31d81d26',\n",
    "    },\n",
    "    Applications=[\n",
    "        {'Name': 'Spark'},\n",
    "    ],\n",
    "    VisibleToAllUsers=True,\n",
    "    JobFlowRole='arn:aws:iam::182424271996:instance-profile/EMR_EC2_DefaultRole', #this is instance profile role\n",
    "    ServiceRole='arn:aws:iam::182424271996:role/EMR_Default_Role',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d513ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List EMR clusters\n",
    "response = emr_client.list_clusters(\n",
    "    ClusterStates=['WAITING']\n",
    ")\n",
    "print(response)\n",
    "cluster_id=response['Clusters'][0]['Id']\n",
    "print(cluster_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82809c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add steps to the cluster ::\n",
    "step_name = 'cust_segmentation_transform_v2'\n",
    "script_location = 's3://cab-data-science-demo/BOTO3/Scripts/customer_segmentation_transform.py' \n",
    "arguments = ['s3://cab-data-science-demo/BOTO3/Input/sales_data.csv', 's3://cab-data-science-demo/BOTO3/Input/customer_data.csv',\n",
    "            's3://cab-data-science-demo/BOTO3/Output/']  \n",
    "\n",
    "step_response = emr_client.add_job_flow_steps(\n",
    "    JobFlowId=cluster_id,\n",
    "    Steps=[\n",
    "        {\n",
    "            'Name': step_name,\n",
    "            'ActionOnFailure': 'CONTINUE',\n",
    "            'HadoopJarStep': {\n",
    "                'Jar': 'command-runner.jar',\n",
    "                'Args': ['spark-submit',\"--deploy-mode\",\"cluster\", script_location] + arguments,\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# spark-submit command: spark submit,--deploy-mode,'cluster',--master\n",
    "step_id = step_response['StepIds'][0]\n",
    "print(f\"Step added with ID: {step_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00425d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
